{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "What is Prompt Engineering?"
      ],
      "metadata": {
        "id": "DIX5nnOtNDZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 --> Prompt engineering as any use of an LLM out-of-the-box    \n",
        "2 --> The means by which LLMs are programmed with prompts.   \n",
        "3 --> An empirical art of composing and formatting the prompt to maximize a model’s performance on a desired task   \n",
        "4 --> want to complete documents, and so you can trick them into performing tasks just by arranging fake documents."
      ],
      "metadata": {
        "id": "aAjcBVaiNJAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import traceback\n",
        "import google.generativeai as genai\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "6p7K2g2bNwCX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain"
      ],
      "metadata": {
        "id": "rotY0cebcbAr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key = \"\")"
      ],
      "metadata": {
        "id": "yIu6q6Jfcvs8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"gemini-pro\")"
      ],
      "metadata": {
        "id": "9XyWf_Qecdlo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type1  \n",
        "Be Descriptive"
      ],
      "metadata": {
        "id": "Fg9UYrSbdZHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = model.generate_content(\"Write me a birthday message for my dad.\")"
      ],
      "metadata": {
        "id": "zJ6AzAojcmWl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response1.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvkRWbaxcr7I",
        "outputId": "79da15fa-a891-40ca-e031-2ac0cbb582c6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dearest Dad,\n",
            "\n",
            "Happy Birthday to the most amazing man I know.\n",
            "\n",
            "From the moment you held me in your arms, I have been filled with love, support, and unwavering admiration. Your guidance has shaped me into the person I am today, and your love has given me the confidence to pursue my dreams.\n",
            "\n",
            "Through every challenge and every triumph, you have been there as my pillar of strength. You have taught me the value of hard work, integrity, and compassion. Your wisdom and sense of humor have brightened my every day.\n",
            "\n",
            "As you celebrate another year of life, I want to express my deepest gratitude for all that you have done for me. You have sacrificed countless hours to provide for our family and have always put our needs before your own.\n",
            "\n",
            "Your love knows no bounds. It is a love that has carried me through life, giving me the strength to face any obstacle. It is a love that has always been there for me, no matter what.\n",
            "\n",
            "Today, I wish you a day filled with joy, laughter, and love. May the coming year bring you health, happiness, and a lifetime of cherished memories.\n",
            "\n",
            "Happy Birthday, Dad. I love you more than words can say.\n",
            "\n",
            "Love always,\n",
            "[Your name]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write me a birthday message for my dad no longer than 200 \\\n",
        "characters. This is a big birthday because he is turning 50. To celebrate, \\\n",
        "I booked us a boys' trip to Cancun. Be sure to include some cheeky humor, he \\\n",
        "loves that."
      ],
      "metadata": {
        "id": "o7P1e5jTdEkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Write me a birthday message for my dad no longer than 200 \\\n",
        "characters. This is a big birthday because he is turning 50. To celebrate, \\\n",
        "I booked us a boys' trip to Cancun. Be sure to include some cheeky humor, he \\\n",
        "loves that.\"\"\""
      ],
      "metadata": {
        "id": "1bA5Gj4qdGxM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = model.generate_content(prompt)"
      ],
      "metadata": {
        "id": "U1t3L2lEdOEL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response1.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHAl1JNUdnEs",
        "outputId": "95061445-d919-43dd-9936-03766ea7cab2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Happy 50th, Dad! May this be the year you stop dyeing your hair and embrace the silver fox! Can't wait to raise a glass (or a coconut) with you in Cancun on your birthday. It's going to be a \"trip\" to remember!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few-shot-prompt"
      ],
      "metadata": {
        "id": "uhzwpwmgdyDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = f\"\"\"Given the title of a Towards Data Science blog article, write a subtitle for it.\n",
        "\n",
        "Title: Prompt Engineering—How to trick AI into solving your problems\n",
        "Subtitle:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "43ZEd_SNec-L"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = model.generate_content(prompt2)"
      ],
      "metadata": {
        "id": "RHscb8eme5Ky"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-TpXMWgje9l6",
        "outputId": "2137d0b1-4339-49b9-d5e4-3248ddec040c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Unleashing the Power of AI through Strategic Prompt Design'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = \"\"\"\n",
        "Given the title of a Towards Data Science blog article, write a subtitle for it.\n",
        "\n",
        "Title: A Practical Introduction to LLMs\n",
        "Subtitle: 3 levels of using LLMs in practice\n",
        "\n",
        "Title: Cracking Open the OpenAI (Python) API\n",
        "Subtitle: A complete beginner-friendly introduction with example code\n",
        "\n",
        "Title: Prompt Engineering-How to trick AI into solving your problems\n",
        "Subtitle:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "A04__m4-fAEH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = model.generate_content(prompt2)"
      ],
      "metadata": {
        "id": "CdzMfOuxfHPQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response2.text.split('Subtitle:')[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QwJEYiXfIyo",
        "outputId": "002b9869-365f-4517-d9e3-ded3eb875a0f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A step-by-step guide to getting the most out of LLMs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type3\n",
        "Use Structured Text"
      ],
      "metadata": {
        "id": "1PF43lO7g8-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3 = \"Write me a recipe for chocolate chip cookies.\""
      ],
      "metadata": {
        "id": "PV3NcuG6g9lU"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response3 = model.generate_content(prompt3)"
      ],
      "metadata": {
        "id": "HejE2WaWhGP1"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response3.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqxx-_tUhJN6",
        "outputId": "34844ee0-d2f5-4a3e-c316-159ab238a7e1"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Ingredients:**\n",
            "\n",
            "* 1 cup (2 sticks) unsalted butter, softened\n",
            "* 2 cups granulated sugar\n",
            "* 2 large eggs\n",
            "* 1 teaspoon vanilla extract\n",
            "* 3 cups all-purpose flour\n",
            "* 1 teaspoon baking soda\n",
            "* 1/2 teaspoon salt\n",
            "* 2 cups semisweet chocolate chips\n",
            "\n",
            "**Instructions:**\n",
            "\n",
            "1. Preheat oven to 375 degrees Fahrenheit (190 degrees Celsius). Line a baking sheet with parchment paper.\n",
            "2. In a large bowl, cream together the butter and sugar until light and fluffy.\n",
            "3. Beat in the eggs one at a time, then stir in the vanilla extract.\n",
            "4. In a separate bowl, whisk together the flour, baking soda, and salt.\n",
            "5. Gradually add the dry ingredients to the wet ingredients, mixing until just combined.\n",
            "6. Fold in the chocolate chips.\n",
            "7. Drop the dough by rounded tablespoons onto the prepared baking sheet, spacing them about 2 inches apart.\n",
            "8. Bake for 10-12 minutes, or until the edges are golden brown and the centers are set.\n",
            "9. Let the cookies cool on the baking sheet for a few minutes before transferring to a wire rack to cool completely.\n",
            "\n",
            "**Tips:**\n",
            "\n",
            "* For chewier cookies, bake for 10 minutes. For crispier cookies, bake for 12 minutes.\n",
            "* If you don't have parchment paper, you can grease the baking sheet with butter or non-stick spray.\n",
            "* For a more intense chocolate flavor, use dark chocolate chips.\n",
            "* You can add other ingredients to your cookies, such as nuts, oatmeal, or dried fruit.\n",
            "* These cookies are best enjoyed fresh, but can be stored in an airtight container at room temperature for up to 3 days.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3 = \"\"\"Create a well-organized recipe for chocolate chip cookies. Use the following formatting elements.\n",
        "\n",
        "**Ingredients**: List the ingredients with precise measurements and formatting.\n",
        "**Instructions**: Provide step-by-step instructions in numbered format, detailing the baking process.\n",
        "**Tips**: Include a separate section with helpful baking tips and possible variations.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DNlNwa9uhMA5"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response3 = model.generate_content(prompt3)"
      ],
      "metadata": {
        "id": "mXphrA7Uhep8"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response3.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFlKLo2chrVy",
        "outputId": "2b32a926-5bd6-4d12-9f26-adb285e50a3f"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Ingredients**:\n",
            "\n",
            "* 2 1/4 cups (281g) all-purpose flour\n",
            "* 1 teaspoon baking soda\n",
            "* 1/2 teaspoon salt\n",
            "* 1 cup (2 sticks / 227g) unsalted butter, softened\n",
            "* 3/4 cup (150g) granulated sugar\n",
            "* 3/4 cup (150g) packed light brown sugar\n",
            "* 1 teaspoon vanilla extract\n",
            "* 2 large eggs\n",
            "* 2 cups (340g) semisweet chocolate chips\n",
            "\n",
            "**Instructions**:\n",
            "\n",
            "1. Preheat oven to 375°F (190°C).\n",
            "2. Line a baking sheet with parchment paper or a silicone mat.\n",
            "3. In a medium bowl, whisk together the flour, baking soda, and salt.\n",
            "4. In a large bowl, cream together the softened butter, granulated sugar, and brown sugar until light and fluffy.\n",
            "5. Beat in the vanilla extract.\n",
            "6. Add the eggs one at a time, mixing well after each addition.\n",
            "7. Gradually add the dry ingredients to the wet ingredients, mixing until just combined.\n",
            "8. Fold in the chocolate chips.\n",
            "9. Using a cookie scoop or two spoons, drop the dough onto the prepared baking sheet, spacing them about 2 inches apart.\n",
            "10. Bake for 10-12 minutes, or until the edges are golden brown and the centers are set.\n",
            "11. Allow the cookies to cool on the baking sheet for a few minutes before transferring to a wire rack to cool completely.\n",
            "\n",
            "**Tips**:\n",
            "\n",
            "* For chewier cookies, bake for 10 minutes. For crispier cookies, bake for 12 minutes.\n",
            "* Add in other mix-ins like nuts, dried fruit, or peanut butter chips for a fun twist.\n",
            "* To make the dough ahead of time, wrap it tightly in plastic wrap and refrigerate for up to 3 days. Bring the dough to room temperature before baking.\n",
            "* For giant cookies, increase the dough size to approximately 1/4 cup per cookie and bake for 15-18 minutes.\n",
            "* Let the cookies cool completely before storing them in an airtight container for up to 3 days at room temperature.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type4    \n",
        "Chain of Thought"
      ],
      "metadata": {
        "id": "cnpNBNx-BGrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Medium_blog_text = \"\"\"\n",
        "I’m thrilled to share that I’ve recently reached a significant milestone in my professional journey. Over the past few months, I've had the opportunity to dive deep into [insert industry or topic, e.g., AI and machine learning], where I’ve honed my skills and expanded my knowledge. From working on [mention a project or achievement] to collaborating with brilliant minds, the experience has been nothing short of transformative.\n",
        "\n",
        "One of the key takeaways from this journey is the power of perseverance and continuous learning. The landscape of [industry or topic] is ever-evolving, and staying ahead requires not just hard work, but also a passion for innovation and growth.\n",
        "\n",
        "I’m incredibly grateful for the support and encouragement from my mentors, colleagues, and network. Your guidance has been invaluable, and I’m excited about what the future holds as I continue to explore new challenges and opportunities.\n",
        "\n",
        "Looking forward to connecting with more like-minded professionals and contributing to the dynamic field of [industry or topic]. Let’s keep pushing the boundaries and making an impact!\n",
        "\n",
        "#GrowthMindset #LearningJourney #Innovation #CareerMilestone #Networking\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "osKeyWzgBPSY"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt4 = f\"\"\"\n",
        "Write me a LinkedIn post based on the following Medium blog.\n",
        "\n",
        "Medium blog: {Medium_blog_text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "06bbJqXe-C4B"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response4 = model.generate_content(prompt4)"
      ],
      "metadata": {
        "id": "0HdBWMd_-z1C"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response4.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i54vWti-22k",
        "outputId": "11b9631b-aa25-4adb-d8ab-4c250f4aa1df"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**LinkedIn Post:**\n",
            "\n",
            "🎉 A significant milestone achieved! Over the past few months, I've immersed myself in [insert industry or topic]. From [mention a project or achievement] to collaborating with exceptional minds, the experience has been immensely transformative.\n",
            "\n",
            "🔑 Perseverance and continuous learning have been essential in navigating the evolving landscape of [industry or topic]. My passion for innovation and growth has kept me driven to push the boundaries.\n",
            "\n",
            "🙏 A huge thank you to my mentors, colleagues, and network for their unwavering support.\n",
            "\n",
            "🚀 As I continue to explore new horizons in [industry or topic], I'm excited to connect with more like-minded professionals. Together, let's shape the future and make a meaningful impact.\n",
            "\n",
            "#GrowthMindset #LearningJourney #Innovation #CareerMilestone #Networking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt4 = f\"\"\"\n",
        "Write me a LinkedIn post based on the step-by-step process and Medium blog \\\n",
        "given below.\n",
        "\n",
        "Step 1: Come up with a one line hook relevant to the blog.\n",
        "Step 2: Extract 3 key points from the article\n",
        "Step 3: Compress each point to less than 50 characters.\n",
        "Step 4: Combine the hook, compressed key points from Step 3, and a call to action \\\n",
        "to generate the final output.\n",
        "\n",
        "Medium blog: {Medium_blog_text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QEGvJntfDNjM"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response4 = model.generate_content(prompt4)"
      ],
      "metadata": {
        "id": "9IXNk5v0DVMT"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response4.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBqzklzMDaQA",
        "outputId": "148a21f9-527b-4193-e7bc-c910c3efd68c"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Step 1: Hook**\n",
            "In a world of relentless change, harness the power of perseverance and continuous learning.\n",
            "\n",
            "**Step 2: Key Points**\n",
            "- Perseverance = Success\n",
            "- Learning = Staying Ahead\n",
            "- Networking = Support\n",
            "\n",
            "**Step 3: Compressed Key Points**\n",
            "- Hustle hard\n",
            "- Learn constantly\n",
            "- Build connections\n",
            "\n",
            "**Step 4: Final Output**\n",
            "**In a world of relentless change, harness the power of perseverance and continuous learning. Hustle hard, learn constantly, and build connections. Join me in pushing boundaries and making an impact!**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type5   \n",
        "Chatbot Personas   \n",
        "you are an expert"
      ],
      "metadata": {
        "id": "96NenuzjDqDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt5 = \"Make me a travel itinerary for a weekend in New York City.\""
      ],
      "metadata": {
        "id": "gbM33GD6Dbzt"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response5 = model.generate_content(prompt5)"
      ],
      "metadata": {
        "id": "cxOTjUDTDyxX"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response5.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSMCe3I1D4ZT",
        "outputId": "1a4169cc-a8df-46fc-b849-ddd99bfeca57"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Day 1**\n",
            "\n",
            "* **Morning:** Arrive in NYC and check into your hotel in Midtown Manhattan.\n",
            "* **Afternoon:** Visit the iconic Empire State Building for panoramic city views. Head to nearby Macy's Herald Square for some shopping.\n",
            "* **Evening:** Dine at a restaurant in Little Italy for authentic Italian cuisine. Consider a stroll through Greenwich Village for live music and nightlife.\n",
            "\n",
            "**Day 2**\n",
            "\n",
            "* **Morning:** Explore Central Park, New York City's sprawling green oasis. Visit Strawberry Fields and the Bethesda Fountain.\n",
            "* **Afternoon:** Take a guided tour of the Statue of Liberty and Ellis Island. Get up close to this symbol of freedom and learn about its history.\n",
            "* **Evening:** Enjoy a Broadway show at one of the many legendary theaters in the Theater District.\n",
            "\n",
            "**Day 3**\n",
            "\n",
            "* **Morning:** Visit the 9/11 Memorial and Museum to remember the tragic events of September 11, 2001.\n",
            "* **Afternoon:** Explore the artsy SoHo neighborhood with its boutiques, galleries, and cobblestone streets.\n",
            "* **Evening:** Have dinner at a restaurant in Tribeca before catching a flight back home.\n",
            "\n",
            "**Accommodation:**\n",
            "\n",
            "* Hotel Pennsylvania (Midtown)\n",
            "* Pod Hotel (East Village)\n",
            "* Holiday Inn Express Manhattan Financial District (Downtown)\n",
            "\n",
            "**Transportation:**\n",
            "\n",
            "* Use the city's subway system or opt for taxis or ride-sharing services.\n",
            "\n",
            "**Food and Drink Recommendations:**\n",
            "\n",
            "* Little Italy: Da Nico or Ferrara Bakery & Cafe\n",
            "* Greenwich Village: Caffe Vivaldi or Washington Square Hotel\n",
            "* Tribeca: Balthazar or Locanda Verde\n",
            "\n",
            "**Tips:**\n",
            "\n",
            "* Book your hotel and Broadway show tickets in advance.\n",
            "* Consider purchasing a CityPASS for discounted admission to top attractions.\n",
            "* Wear comfortable shoes as you will be doing a lot of walking.\n",
            "* Respect the locals and be aware of your surroundings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt5= \"\"\"\n",
        "Act as an NYC native and cabbie who knows everything about the city. \\\n",
        "Please make me a travel itinerary for a weekend in New York City based on \\\n",
        "your experience. Don't forget to include your charming NY accent in your \\\n",
        "response.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9C_MEM8sD6i9"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response5 = model.generate_content(prompt5)"
      ],
      "metadata": {
        "id": "OyfMjd4XED4g"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response5.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GUkDDISEFu4",
        "outputId": "b276eaaf-f84d-4b67-ffd8-b17fcb12366b"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, my friend, listen up! I'm gonna give ya the lowdown on the best weekend in the greatest city on Earth: New York City.\n",
            "\n",
            "**Friday:**\n",
            "\n",
            "* **Daytime:** Kick off with a stroll through Central Park, the Big Apple's green oasis. Rent a rowboat on the Lake or just chill out on the Great Lawn.\n",
            "* **Evening:** Head to Times Square for a dose of the city's bright lights and billboards. Grab tickets for a Broadway show or explore the museums in the Theater District.\n",
            "\n",
            "**Saturday:**\n",
            "\n",
            "* **Daytime:** Visit the iconic Empire State Building or One World Trade Center for panoramic views. Then, wander down 5th Avenue for some serious shopping.\n",
            "* **Evening:** Experience the city's vibrant nightlife in the Meatpacking District or the East Village. Check out live music venues, rooftop bars, or dive into the club scene.\n",
            "\n",
            "**Sunday:**\n",
            "\n",
            "* **Daytime:** Start the day with a bagel and schmear from a local deli. Explore the Museum of Modern Art (MoMA) or the American Museum of Natural History.\n",
            "* **Afternoon:** Take a ferry to the Statue of Liberty and Ellis Island for a taste of history. End your weekend with a stroll along the Brooklyn Bridge, soaking in the city skyline.\n",
            "\n",
            "**Food:**\n",
            "\n",
            "* **Breakfast:** Russ & Daughters for iconic Jewish delicacies\n",
            "* **Lunch:** Katz's Delicatessen for piled-high pastrami sandwiches\n",
            "* **Dinner:** Peter Luger Steak House for legendary steak\n",
            "* **Snacks:** Pretzels from a street vendor, pizza from Joe's Pizza\n",
            "\n",
            "**Tips from a Local:**\n",
            "\n",
            "* **Transportation:** Use the subway or ride-sharing apps to get around easily.\n",
            "* **Accommodation:** Stay in Midtown Manhattan for central access to attractions.\n",
            "* **Weather:** NYC weather can be unpredictable, so pack for all seasons.\n",
            "* **Attitude:** Embrace the city's hustle and bustle, and don't be afraid to ask for help.\n",
            "\n",
            "And there you have it, my friend! A weekend in the Big Apple that'll leave you craving for more. Enjoy the ride!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FKzJ4bCPEHQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type6   \n",
        "Flipped Approach    \n",
        "we do not know what it knows or how it thinks."
      ],
      "metadata": {
        "id": "kGBC-qgUES0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt6 = \"What is an idea for an LLM-based application?\""
      ],
      "metadata": {
        "id": "gTZnj2hJEVCl"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response6 = model.generate_content(prompt6)"
      ],
      "metadata": {
        "id": "XbJOmFtVEazH"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response6.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55QM2SELEuFP",
        "outputId": "153fb0c4-0f78-4ccc-9a12-64f8ca6a4cbc"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Personalized Educational Assistant**\n",
            "\n",
            "**Description:**\n",
            "\n",
            "An AI-powered application that provides tailored learning experiences and support for students based on their individual needs and goals.\n",
            "\n",
            "**Features:**\n",
            "\n",
            "* **Personalized Learning Plan:** Create customized learning paths based on student's learning style, strengths, and weaknesses.\n",
            "* **Adaptive Content:** Generate study materials and assignments that align with the student's current understanding and progress.\n",
            "* **Real-Time Feedback:** Provide immediate and personalized feedback on student responses, identifying areas for improvement.\n",
            "* **Skill Assessments:** Regularly evaluate student progress and provide insights into areas that need further development.\n",
            "* **Educational Resource Library:** Access a curated collection of high-quality educational resources, videos, and articles.\n",
            "* **Mentor Matching:** Connect students with mentors who can provide guidance and support based on their specific field of interest or career path.\n",
            "\n",
            "**Benefits:**\n",
            "\n",
            "* **Personalized Learning:** Tailors education to each student's unique needs, maximizing their learning potential.\n",
            "* **Improved Engagement:** Makes learning more engaging and motivating by providing relevant and challenging content.\n",
            "* **Efficient Studying:** Helps students optimize their study time by focusing on areas where they need the most support.\n",
            "* **Empowered Students:** Gives students a sense of control over their own learning and empowers them to take ownership of their academic journey.\n",
            "* **Teacher Collaboration:** Supports teachers by providing them with insights into student progress and facilitating personalized instruction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt6 = \"\"\"\n",
        "I want you to ask me questions to help me come up with an LLM-based \\\n",
        "application idea. Ask me one question at a time to keep things conversational.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bzVBSiKREwsr"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response6 = model.generate_content(prompt6)"
      ],
      "metadata": {
        "id": "B96KXb3QE68s"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response6.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvApluWyFD2T",
        "outputId": "02133722-29a6-4235-ed17-19b066e09308"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, I can help you with that. Let's start with a few questions to get the conversation going:\n",
            "\n",
            "1. What are some of your interests and hobbies?\n",
            "2. What kind of problems do you often encounter in your daily life or work?\n",
            "3. Are there any tasks that you find repetitive or time-consuming?\n",
            "4. What are some of the challenges or pain points you face in your industry or field?\n",
            "5. What kind of information or data do you frequently need access to?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NbryakslFFg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type 7:    \n",
        "Reflect, Review, and Refine"
      ],
      "metadata": {
        "id": "8roZZ8Z8FRnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt7 = \"\"\"\n",
        "Review your previous response, pinpoint areas for enhancement, and offer an \\\n",
        "improved version. Then explain your reasoning for how you improved the response.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "upZlhllHFVHb"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response7 = model.generate_content(prompt7)"
      ],
      "metadata": {
        "id": "UeMqCd57FbnQ"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response7.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTlaTtlmFfEe",
        "outputId": "763283f8-c8b1-44aa-f250-5e5b3a6b4243"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Original Response:**\n",
            "\n",
            "Generating a report on the financial performance of a company over the last five years is a multi-faceted task that requires careful analysis of various financial statements. Here are the steps to follow:\n",
            "\n",
            "1. **Gather financial statements:** Collect the company's income statements, balance sheets, and cash flow statements for the past five years.\n",
            "2. **Analyze income statements:** Review revenue trends, gross profit margins, operating expenses, and net income. Identify key drivers of profitability and areas for improvement.\n",
            "3. **Analyze balance sheets:** Examine assets, liabilities, and equity. Assess the company's financial leverage, liquidity, and solvency.\n",
            "4. **Analyze cash flow statements:** Track the flow of cash from operations, investments, and financing activities. Identify sources and uses of cash and assess the company's liquidity.\n",
            "5. **Conduct trend analysis:** Compare financial ratios and metrics over the five-year period to identify trends and patterns. Highlight areas of growth, decline, or stability.\n",
            "6. **Write the report:** Organize the findings from the analysis into a comprehensive report. Provide clear explanations of the financial performance, trends, and areas for improvement. Include relevant charts and graphs to illustrate key insights.\n",
            "\n",
            "**Improved Response:**\n",
            "\n",
            "**Enhanced Steps for Generating a Comprehensive Financial Performance Report:**\n",
            "\n",
            "1. **Gather comprehensive financial data:** Collect income statements, balance sheets, cash flow statements, and any other relevant financial reports for the past five years.\n",
            "2. **Conduct a thorough analysis of income statements:** Analyze revenue growth rates, gross profit margins, expense structures, and net income trends. Identify key revenue drivers, cost drivers, and areas of profitability improvement.\n",
            "3. **Perform an in-depth analysis of balance sheets:** Examine asset growth, liability composition, and equity changes. Evaluate the company's liquidity, solvency, and financial leverage. Assess the impact of balance sheet items on financial performance.\n",
            "4. **Analyze cash flow statements meticulously:** Trace the flow of cash from operations, investments, and financing activities. Identify sources and uses of cash, and assess the company's cash management efficiency and liquidity.\n",
            "5. **Conduct a comprehensive trend analysis:** Calculate and compare key financial ratios and metrics, such as profit margins, return on assets, and leverage ratios, over the five-year period. Identify trends, patterns, and areas of improvement or concern.\n",
            "6. **Prepare a well-organized and insightful report:** Organize the findings from the analysis into a coherent and comprehensive report. Provide clear explanations and interpretations of the financial performance, trends, and areas for improvement. Support the analysis with relevant charts, graphs, and tables to illustrate key insights and facilitate understanding.\n",
            "\n",
            "**Reasoning for Enhancements:**\n",
            "\n",
            "The improved response provides more detailed and comprehensive steps to enhance the quality and depth of the financial performance report.\n",
            "\n",
            "* **Enhanced Step 1:** Emphasizes the importance of gathering comprehensive financial data, not just the core financial statements.\n",
            "* **Enhanced Step 2:** Adds \"revenue growth rates\" and \"expense structures\" to the analysis of income statements, providing a more thorough examination of profitability drivers.\n",
            "* **Enhanced Step 3:** Includes \"asset growth\" and \"liability composition\" in the analysis of balance sheets, giving a more comprehensive view of the company's financial health.\n",
            "* **Enhanced Step 4:** Adds \"cash management efficiency\" to the analysis of cash flow statements, highlighting the company's ability to manage its cash resources.\n",
            "* **Enhanced Step 5:** Expands the trend analysis to include \"leverage ratios,\" providing insights into the company's financial risk.\n",
            "* **Enhanced Step 6:** Emphasizes the importance of organizing the findings into a \"coherent and comprehensive report\" and providing clear explanations and interpretations, ensuring that the report is well-structured and easy to understand.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "why we need PE"
      ],
      "metadata": {
        "id": "QW7KjcRsQbn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who was the 35th president of the United States of America?\"\n",
        "correct_answer = \"John Fitzgerald Kennedy\"\n",
        "student_answer = \"JFK\""
      ],
      "metadata": {
        "id": "gY3hObUtQUVX"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"You are a high school history teacher grading homework assignments. \\\n",
        "Based on the homework question indicated by “Q:” and the correct answer \\\n",
        "indicated by “A:”, your task is to determine whether the student's answer is \\\n",
        "correct.\n",
        "Grading is binary; therefore, student answers can be correct or wrong.\n",
        "Simple misspellings are okay.\n",
        "\n",
        "Q: {question}\n",
        "A: {correct_answer}\n",
        "\n",
        "Student Answer: {student_answer}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wqTl4l-GFjkL"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = model.generate_content(prompt)"
      ],
      "metadata": {
        "id": "Aw2VA8WxQz-6"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(teacher.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPtmTbSGRATw",
        "outputId": "13a218b6-f11c-41b4-bfd6-12aae069a8fa"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain_community\n",
        "# !pip install langchain\n",
        "# !pip install langchain_google_genai\n"
      ],
      "metadata": {
        "id": "XAaO5N47RECq"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langchain"
      ],
      "metadata": {
        "id": "V38pTIj0buGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "import pandas as pd\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema import BaseOutputParser"
      ],
      "metadata": {
        "id": "YCNgGBuUbvZu"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KEY = os.getenv(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "tVsS3sZGbv80"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR0z5abBctXo",
        "outputId": "06739df1-4f6c-4cdc-ebee-1e0fad7b7a7e"
      },
      "execution_count": 165,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             temperature=0, convert_system_message_to_human=True)"
      ],
      "metadata": {
        "id": "2-mLjuIOcvDB"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define prompt template\n",
        "prompt_template_text = \"\"\"You are a high school history teacher grading \\\n",
        "homework assignments. Based on the homework question indicated by “**Q:**” \\\n",
        "and the correct answer indicated by “**A:**”, your task is to determine \\\n",
        "whether the student's answer is correct. Grading is binary; therefore, \\\n",
        "student answers can be correct or wrong. Simple misspellings are okay.\n",
        "\n",
        "**Q:** {question}\n",
        "**A:** {correct_answer}\n",
        "\n",
        "**Student's Answer:** {student_answer}\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "pcHH3pRuc63f"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "            input_variables=[\"question\", \"correct_answer\", \"student_answer\"], \\\n",
        "            template = prompt_template_text)"
      ],
      "metadata": {
        "id": "ISI_xahpdGlw"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zDCDWVpdIaP",
        "outputId": "2ebcfe41-7fa7-425e-f7f6-51f90ecbf5a0"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-170-726db833e4be>:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define inputs\n",
        "question = \"Who was the 35th president of the United States of America?\"\n",
        "correct_answer = \"John F. Kennedy\"\n",
        "student_answer =  \"JFK\""
      ],
      "metadata": {
        "id": "d70GNRlTdSr0"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run chain\n",
        "ans = chain.run({'question':question, 'correct_answer':correct_answer, \\\n",
        "    'student_answer':student_answer})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFwPzml-d3yS",
        "outputId": "a9082e32-0e36-4eea-de87-d11d5ed86071"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G882_h8IeHIR",
        "outputId": "23867b2a-ef67-42f5-d427-e1b8c4482645"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Parser**   \n"
      ],
      "metadata": {
        "id": "EjQJgyJee5fB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model output in some format like string,small characters"
      ],
      "metadata": {
        "id": "kZsq7HTa3Cj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define output parser\n",
        "class GradeOutputParser(BaseOutputParser):\n",
        "    \"\"\"Determine whether grade was correct or wrong\"\"\"\n",
        "\n",
        "    def parse(self, text: str):\n",
        "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
        "        return \"wrong\" not in text.lower()"
      ],
      "metadata": {
        "id": "-9t2h--wfAra"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# update chain\n",
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    output_parser=GradeOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "7ifFKKAcfGfQ"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run chain in for loop\n",
        "student_answer_list = [\"John F. Kennedy\", \"JFK\", \"FDR\", \"John F. Kenedy\", \\\n",
        "                  \"John Kennedy\", \"Jack Kennedy\", \"Jacquelin Kennedy\", \\\n",
        "                  \"Robert F. Kenedy\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "qiowYN_1fYt6"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = {}\n",
        "for student_answer in student_answer_list:\n",
        "  ans = chain.run({'question':question, 'correct_answer':correct_answer,'student_answer':student_answer})\n",
        "  history[student_answer] = ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eVbOl4qfodr",
        "outputId": "8870a3fa-1b29-42f6-8a13-08d583b08478"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:381: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in history:\n",
        "  print(key ,\"---->\",history[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N4YS287f0RL",
        "outputId": "fddeeea9-8091-4429-e304-f97beabc8332"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John F. Kennedy ----> True\n",
            "JFK ----> True\n",
            "FDR ----> False\n",
            "John F. Kenedy ----> True\n",
            "John Kennedy ----> True\n",
            "Jack Kennedy ----> True\n",
            "Jacquelin Kennedy ----> False\n",
            "Robert F. Kenedy ----> False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wikipedia"
      ],
      "metadata": {
        "id": "ez-RkBaDxdPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chain-of-Symbol (CoS) Prompting**"
      ],
      "metadata": {
        "id": "jmm8-R_B0V0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input:\n",
        "\n",
        "There are a set of bricks. The yellow brick C is on top of the brick E. The yellow brick D is on top of the brick A. The yellow brick E is on top of the brick D. The white brick A is on top of the brick B. For the brick B, the color is white. Now we have to get a specific brick. The bricks must now be grabbed from top to bottom, and if the lower brick is to be grabbed, the upper brick must be removed first. How to get brick D?\n",
        "\n",
        "B/A/D/E/C\n",
        "C/E\n",
        "E/D\n",
        "D\n",
        "\n",
        "Output:\n",
        "\n",
        "So we get the result as C, E, D."
      ],
      "metadata": {
        "id": "R9NNCGnL0dyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Input:\n",
        "\n",
        "There are a set of bricks. The yellow brick C is on top of the brick E.\n",
        "The yellow brick D is on top of the brick A. The yellow brick E is on top of the brick D.\n",
        "The white brick A is on top of the brick B. For the brick B, the color is white.\n",
        "Now we have to get a specific brick. The bricks must now be grabbed from top to\n",
        "bottom, and if the lower brick is to be grabbed, the upper brick must be removed first. How to get brick D?\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "J8293qzLxewj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = model.generate_content(prompt)"
      ],
      "metadata": {
        "id": "jLQFlUBC1Rd0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ans.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uguqzNK91VPq",
        "outputId": "f362c530-218c-4ba2-f311-a70354ad44f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First remove C, then remove E, then we can take brick D.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generated knowledge prompting**"
      ],
      "metadata": {
        "id": "72Uz-DxJ1y0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   Generate some knowledge about the concepts in the input.    \n",
        "   Input: {question}    \n",
        "   Knowledge:  "
      ],
      "metadata": {
        "id": "GLxQ5X_G1-W0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Least-to-most prompting**"
      ],
      "metadata": {
        "id": "qeuymZUQ2TGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Q: {question}    \n",
        "   A: Let's break down this problem:    \n",
        "       1.  "
      ],
      "metadata": {
        "id": "dSSZth_a2UpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self-refine**"
      ],
      "metadata": {
        "id": "EsPFU7-b4l6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Step---1    \n",
        "  I have some code. Give one suggestion to improve readability.Don't  \n",
        "  fix the code, just give a suggestion.   \n",
        "   Code: {code}   \n",
        "   Suggestion:   "
      ],
      "metadata": {
        "id": "JHkd9n4p4rmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step2 --->    \n",
        "   Code: {code}   \n",
        "   Let's use this suggestion to improve the code.   \n",
        "   Suggestion: {suggestion}   \n",
        "   New Code:   "
      ],
      "metadata": {
        "id": "_Wf78BgT49EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using language models to generate prompts**"
      ],
      "metadata": {
        "id": "4PwNLMYz8-A1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   \n",
        "Large language models (LLM) themselves can be used to compose prompts for large language models.  \n",
        "\n",
        "The automatic prompt engineer algorithm uses one LLM to beam search   over prompts for another LLM:   \n",
        "\n",
        "1-->There are two LLMs. One is the target LLM, and another is the   prompting LLM.  \n",
        "2-->Prompting LLM is presented with example input-output pairs, and asked  to generate instructions that could have caused a model following the  instructions to generate the outputs, given the inputs.  \n",
        "3-->Each of the generated instructions is used to prompt the target LLM,  followed by each of the inputs. The log-probabilities of the outputs  are computed and added. This is the score of the instruction.\n",
        "\n",
        "4-->The highest-scored instructions are given to the prompting LLM for  further variations.  "
      ],
      "metadata": {
        "id": "gbOmyQLg5ISG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V2XAjq3G8ilA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}